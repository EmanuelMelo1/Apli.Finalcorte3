{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEnV_gpLu46N"
      },
      "outputs": [],
      "source": [
        "# Importamos las librerías necesarias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3OOxwG8Yit-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNKHQWOezsQY",
        "outputId": "452a16ac-4e40-468f-bf48-3cbfc1b158c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Diplomado IA/IMDB Dataset.csv')\n",
        "\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "zVxxQz38zipS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Limpieza de datos#\n",
        "def clean_text(text):\n",
        "    text = BeautifulSoup(text, \"html.parser\").get_text()  # Elimina HTML\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Elimina puntuación\n",
        "    text = text.lower()  # Convierte a minúsculas\n",
        "    return text\n",
        "\n",
        "df['review'] = df['review'].apply(clean_text)\n",
        "print(\"Datos después de la limpieza de texto:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "6tnIhEim2W5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODELO\n",
        "le = LabelEncoder()\n",
        "df['sentiment'] = le.fit_transform(df['sentiment'])\n",
        "\n",
        "X = df['review']\n",
        "y = df['sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "modelo = LogisticRegression()\n",
        "modelo.fit(X_train_tfidf, y_train)\n",
        "\n",
        "puntajes_validacion_cruzada = cross_val_score(modelo, X_train_tfidf, y_train, cv=5)\n",
        "print(\"Puntajes de Validación Cruzada:\", puntajes_validacion_cruzada)\n",
        "print(\"Puntaje Promedio de Validación Cruzada:\", np.mean(puntajes_validacion_cruzada))\n",
        "\n",
        "y_prediccion = modelo.predict(X_test_tfidf)\n",
        "\n",
        "exactitud = accuracy_score(y_test, y_prediccion)\n",
        "informe_clasificacion = classification_report(y_test, y_prediccion)\n",
        "matriz_confusion = confusion_matrix(y_test, y_prediccion)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(matriz_confusion, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.xlabel(\"Predicho\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.title(\"Matriz de Confusión\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ZZCk54Gm3ngw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PRUEBA\n",
        "precision_modelo = accuracy_score(y_test, y_prediccion)\n",
        "\n",
        "\n",
        "if precision_modelo > 0.82:\n",
        "    print(\"El modelo cumple con el requisito de precisión (> 0.82).\")\n",
        "else:\n",
        "    print(\"El modelo no cumple con el requisito de precisión (> 0.82).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9lNlsRC6zrj",
        "outputId": "ec72a523-e75e-419d-a1a5-bbbc28b0ce55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El modelo cumple con el requisito de precisión (> 0.82).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PICKLE"
      ],
      "metadata": {
        "id": "V8e8QoN0Ab37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "-anAdn0SArHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open('logistic_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(modelo, model_file)\n",
        "\n",
        "with open('tfidf_vectorizer.pkl', 'wb') as vectorizer_file:\n",
        "    pickle.dump(tfidf_vectorizer, vectorizer_file)"
      ],
      "metadata": {
        "id": "mfoSquoKAd1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STREAMLIT\n",
        "! pip install streamlit"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SzoDKwBcUsqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit -q"
      ],
      "metadata": {
        "collapsed": true,
        "id": "noqn_YGiJuz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit-lottie"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XaFAXdwSKG7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pickle\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "# Cargar el modelo y el vectorizador TF-IDF\n",
        "with open('logistic_model.pkl', 'rb') as model_file:\n",
        "    modelo = pickle.load(model_file)\n",
        "\n",
        "with open('tfidf_vectorizer.pkl', 'rb') as vectorizer_file:\n",
        "    tfidf_vectorizer = pickle.load(vectorizer_file)\n",
        "\n",
        "st.title(\"Predict Reviews' Sentiment\")\n",
        "\n",
        "# Entrada de la reseña\n",
        "review = st.text_input(\"Ingrese la reseña:\")\n",
        "\n",
        "if st.button(\"Predicción\"):\n",
        "    # Preprocesar y vectorizar la reseña\n",
        "    review_cleaned = BeautifulSoup(review, \"html.parser\").get_text()\n",
        "    review_cleaned = re.sub(r'[^\\w\\s]', '', review_cleaned)\n",
        "    review_cleaned = review_cleaned.lower()\n",
        "    review_vectorized = tfidf_vectorizer.transform([review_cleaned])\n",
        "\n",
        "    # Predicción\n",
        "    pred = modelo.predict(review_vectorized)[0]\n",
        "\n",
        "    if pred == 0:\n",
        "        st.write(\"La reseña es Negativa\")\n",
        "    else:\n",
        "        st.write(\"La reseña es Positiva\")"
      ],
      "metadata": {
        "id": "p96xWfhAKlgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "dHjnHh7kW8DQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}